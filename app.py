import streamlit as st
from src.tools import graph  # Importa el grafo con memoria
import uuid  # Para generar IDs √∫nicos
from src.architecture_rag import get

# Configuraci√≥n inicial de la p√°gina
st.set_page_config(page_title="Asistente Virtual", layout="wide")
st.title("üìÑ Asistente Virtual basado para la DIAN")
st.markdown("Este asistente responde preguntas basadas en el contenido de los documentos PDF cargados.")

# Entrada del usuario para buscar por categor√≠a
st.sidebar.header("Buscar Documentos por Categor√≠a")
category_query = st.sidebar.text_input("T√©rmino de b√∫squeda (ej. 'legal'):")
num_results = st.sidebar.number_input("N√∫mero de resultados:", min_value=1, value=5)

if st.sidebar.button("Buscar Documentos"):
    with st.spinner("Buscando documentos..."):
        # Buscar documentos relacionados con la categor√≠a
        retrieved_docs = get(category_query, k=num_results)

        # Mostrar los resultados
        st.subheader(f"üîç Documentos Relacionados con '{category_query}':")
        for doc in retrieved_docs:
            st.write(f"**Metadata:** {doc.metadata}")
            st.write(f"**Content:** {doc.page_content}")
            st.markdown("---")

# Genera un thread_id √∫nico para la sesi√≥n actual
if "thread_id" not in st.session_state:
    st.session_state.thread_id = str(uuid.uuid4())  # Genera un ID √∫nico

# Inicializa el historial de mensajes si no existe
if "message_history" not in st.session_state:
    st.session_state.message_history = []

# Mostrar el historial de mensajes en la parte principal
for msg in st.session_state.message_history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# Entrada de texto en la parte inferior
query = st.chat_input(placeholder="Escribe tu pregunta aqu√≠...")

if query:
    # Agrega el mensaje del usuario al historial
    st.session_state.message_history.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.write(query)

    # Ejecutar el flujo en el grafo
    with st.spinner("Buscando respuesta..."):
        response = None
        for step in graph.stream(
            {"messages": st.session_state.message_history},
            config={"configurable": {"thread_id": st.session_state.thread_id}},  # Proporciona el thread_id
            stream_mode="values",
        ):
            response = step["messages"][-1].content  # Obtener la √∫ltima respuesta

        # Agrega la respuesta del modelo al historial
        st.session_state.message_history.append({"role": "assistant", "content": response})

        # Muestra la respuesta del asistente
        with st.chat_message("assistant"):
            st.write(response)